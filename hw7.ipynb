{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPa1NdldF19T9TF6IXZYFON",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gferew1/IntroML/blob/main/hw7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "# Check for CUDA availability and set the device\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. Using GPU.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Using CPU.\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxs1nj97ik3K",
        "outputId": "84b6c3a6-9b21-4d73-f56a-2736ecfeb09a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available. Using GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.act3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.act1(self.conv1(x)))\n",
        "        x = self.pool2(self.act2(self.conv2(x)))\n",
        "        x = x.view(-1, 8 * 8 * 8)\n",
        "        x = self.act3(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "NZPSirUrine3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare CIFAR-10 dataset\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "cifar10 = datasets.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(cifar10, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(cifar10_val, batch_size=64, shuffle=False)\n",
        "\n",
        "# Setup the model, optimizer, and loss function\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QnTZicujfF3",
        "outputId": "8444f94a-46ff-4ff9-80e0-8273655396eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 64326900.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data-unversioned/p1ch6/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables for metrics\n",
        "total_training_time = 0\n",
        "epoch_losses = []\n",
        "\n",
        "# Modified training loop to record metrics\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    global total_training_time\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        end_time = time.time()\n",
        "        total_training_time += end_time - start_time\n",
        "        epoch_loss = loss_train / len(train_loader)\n",
        "        epoch_losses.append(epoch_loss)\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0 or epoch == n_epochs:\n",
        "            print(f'Epoch {epoch}, Training loss {epoch_loss}')\n"
      ],
      "metadata": {
        "id": "zJGmsLLgjiMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "training_loop(\n",
        "    n_epochs=300,\n",
        "    optimizer=optimizer,\n",
        "    model=model,\n",
        "    loss_fn=loss_fn,\n",
        "    train_loader=train_loader\n",
        ")\n",
        "\n",
        "# Modified validation to record accuracy\n",
        "def validate(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += int((predicted == labels).sum())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "accuracy = validate(model, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf7hhCHYjmpG",
        "outputId": "03f02a28-ba88-4952-a09c-91b3d6f4456c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 2.118343261958998\n",
            "Epoch 10, Training loss 1.125154920627394\n",
            "Epoch 20, Training loss 0.9513692104298136\n",
            "Epoch 30, Training loss 0.8682655227153807\n",
            "Epoch 40, Training loss 0.811758241956801\n",
            "Epoch 50, Training loss 0.7684587559203053\n",
            "Epoch 60, Training loss 0.7352390052260035\n",
            "Epoch 70, Training loss 0.7066352240493535\n",
            "Epoch 80, Training loss 0.685337789108991\n",
            "Epoch 90, Training loss 0.6661190847149285\n",
            "Epoch 100, Training loss 0.6541597452538702\n",
            "Epoch 110, Training loss 0.638415762797341\n",
            "Epoch 120, Training loss 0.6307086101578324\n",
            "Epoch 130, Training loss 0.6205525988965388\n",
            "Epoch 140, Training loss 0.6125045066599346\n",
            "Epoch 150, Training loss 0.6056700305789328\n",
            "Epoch 160, Training loss 0.5984811785885745\n",
            "Epoch 170, Training loss 0.5906635256831908\n",
            "Epoch 180, Training loss 0.5853971571035093\n",
            "Epoch 190, Training loss 0.5827668143050445\n",
            "Epoch 200, Training loss 0.5761483353574562\n",
            "Epoch 210, Training loss 0.5710281148514784\n",
            "Epoch 220, Training loss 0.5656265297814098\n",
            "Epoch 230, Training loss 0.56284345074764\n",
            "Epoch 240, Training loss 0.5588170251882899\n",
            "Epoch 250, Training loss 0.5547811650787778\n",
            "Epoch 260, Training loss 0.5512264309179448\n",
            "Epoch 270, Training loss 0.5488079005609388\n",
            "Epoch 280, Training loss 0.5460457964931302\n",
            "Epoch 290, Training loss 0.5454009793641622\n",
            "Epoch 300, Training loss 0.5421632675411147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print or save the metrics\n",
        "print(f\"Total Training Time: {total_training_time:.2f} seconds\")\n",
        "print(f\"Training Losses Over Epochs: {epoch_losses}\")\n",
        "print(f\"Evaluation Accuracy after 300 epochs: {accuracy}\")\n",
        "\n",
        "# Optionally, write these metrics to a file\n",
        "with open(\"training_metrics.txt\", \"w\") as file:\n",
        "    file.write(f\"Total Training Time: {total_training_time:.2f} seconds\\n\")\n",
        "    file.write(f\"Training Losses Over Epochs: {epoch_losses}\\n\")\n",
        "    file.write(f\"Evaluation Accuracy after 300 epochs: {accuracy}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcH5ACzqjpoG",
        "outputId": "2fa99561-f67b-486a-b26e-214432376b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Training Time: 4890.97 seconds\n",
            "Training Losses Over Epochs: [2.118343261958998, 1.7179432755236126, 1.508513274552572, 1.400537279103418, 1.3360878798510412, 1.2852853150928722, 1.2360740129447654, 1.1944039476954418, 1.1558052023201038, 1.125154920627394, 1.097100122734104, 1.0740516966261218, 1.053207089833896, 1.0346937468442161, 1.016857335558328, 0.999689489145718, 0.9868245939616962, 0.9738566210050412, 0.9635792382995186, 0.9513692104298136, 0.9423371936811511, 0.9317797913270838, 0.9222343018292771, 0.9113693046752754, 0.9055778487868931, 0.8969689478044924, 0.8908786384193489, 0.8827549496956189, 0.877424971526846, 0.8682655227153807, 0.8611227911527809, 0.8540788391209624, 0.8481679895649785, 0.8429487195542401, 0.8407381045086609, 0.8319511379274871, 0.8274875577453458, 0.819866128094361, 0.8165901345974954, 0.811758241956801, 0.8069056266790156, 0.8003277340356041, 0.7981083213215898, 0.7929411341848276, 0.7875303808228135, 0.7837374993526113, 0.7809744037097067, 0.7760774642991288, 0.7725723963183211, 0.7684587559203053, 0.7610637196494491, 0.7562124363296782, 0.7543429624470298, 0.7522454588385799, 0.7475047208692717, 0.7449894255536902, 0.7414102593574987, 0.7392490461201924, 0.7368137640187807, 0.7352390052260035, 0.728438629976014, 0.728321584175005, 0.724405076993091, 0.7208943693991512, 0.7175023950579221, 0.7144479978343715, 0.7132968228034047, 0.7121432219701045, 0.7092637699049757, 0.7066352240493535, 0.7047528886734067, 0.7011248844358927, 0.7009841694551355, 0.6959181151655324, 0.6944207579964568, 0.6957503026327514, 0.6917200542014578, 0.6884169712700807, 0.6873544259449406, 0.685337789108991, 0.6822968757213534, 0.6805902606309833, 0.6801520030364356, 0.6785300804297333, 0.6746888773711136, 0.6736739308709074, 0.670765285868474, 0.6711575512386039, 0.6697408825235294, 0.6661190847149285, 0.6649225204420821, 0.6643619678361946, 0.6627196596787713, 0.6614640878746881, 0.6597394892931594, 0.6582913958203153, 0.6563293696059596, 0.6542465041589249, 0.6549849045246153, 0.6541597452538702, 0.6509393865952406, 0.6495996104253222, 0.6489462785403747, 0.6483906507110961, 0.6479322062733838, 0.6435611241537592, 0.6429717321225139, 0.643398997728782, 0.6407751788568619, 0.638415762797341, 0.639864408261026, 0.637651572561325, 0.6383669010513578, 0.637317745772469, 0.6360574784638632, 0.6338499980356992, 0.6332448971698351, 0.6342632476707248, 0.6300907673890633, 0.6307086101578324, 0.6308364617016614, 0.6299382430665633, 0.6274044323912666, 0.6278556493846962, 0.6242525919395334, 0.6240163132205339, 0.6227333851139564, 0.6202860594253101, 0.623660332673346, 0.6205525988965388, 0.620576894915927, 0.6201338297723199, 0.6191526290477084, 0.6171748122138441, 0.6175360739078668, 0.6160649517003227, 0.6149976179194268, 0.615148599952688, 0.6152702422093248, 0.6125045066599346, 0.6099194051969387, 0.6089942223961701, 0.610451914770219, 0.6121034066924049, 0.6081551979569828, 0.6086630870009322, 0.6068696261519362, 0.6060205520418904, 0.605198146818239, 0.6056700305789328, 0.6054761267607779, 0.6035205244332018, 0.6024494905529729, 0.601038859285357, 0.6020892667191108, 0.5983991219716913, 0.6001399025664, 0.5993168400910199, 0.5988191164210629, 0.5984811785885745, 0.5990169985062631, 0.5974544813604001, 0.5979807715281806, 0.5942933083418995, 0.5959118013567937, 0.5950138896055843, 0.5917274602843673, 0.5931492091139869, 0.5950653149420039, 0.5906635256831908, 0.5910102870229565, 0.5899052541045582, 0.5915470758591161, 0.5905046226347194, 0.5886765574021717, 0.5902370608523678, 0.5873774277508411, 0.5858964399837167, 0.5859468031646041, 0.5853971571035093, 0.5869600939400056, 0.5844001475807346, 0.5840083983776819, 0.5819409219047907, 0.5850118437348424, 0.5839922394975067, 0.5830558506805269, 0.5829750007909277, 0.5785436067358612, 0.5827668143050445, 0.5816518593474728, 0.5810004241402497, 0.5802666588550638, 0.5808612708850285, 0.5781638949080501, 0.5773326831934092, 0.5758674730501516, 0.5758447054859317, 0.5782067255138437, 0.5761483353574562, 0.5728969147900487, 0.5759486515275047, 0.5726499148951772, 0.5740210157449898, 0.572809087041089, 0.5741231809263034, 0.5734569293916073, 0.5715365029890519, 0.5711775783763822, 0.5710281148514784, 0.5721134423180614, 0.5725443286968924, 0.5699670088413121, 0.5682216652137849, 0.5708589161296025, 0.5696971182856718, 0.5687345047969647, 0.5679485243375954, 0.5665240856578283, 0.5656265297814098, 0.5671042698576018, 0.5654669064847405, 0.5646592166913135, 0.5656545162200928, 0.5639670475212204, 0.5662082285451158, 0.5654475540303818, 0.5618224468301324, 0.5639394287143826, 0.56284345074764, 0.5630097234111917, 0.5633344953817785, 0.5626659308324384, 0.5592409709606634, 0.5592826471075683, 0.5622410791380631, 0.5599001209296839, 0.5620518575429612, 0.558699918296331, 0.5588170251882899, 0.5594975799703232, 0.5593081807045985, 0.5588061245887176, 0.5574714701498866, 0.5590594985029277, 0.5556323643764267, 0.5572290173958024, 0.556732933272791, 0.5559743328586869, 0.5547811650787778, 0.5556308013551375, 0.5552188074954635, 0.5555189337648089, 0.5555242184177994, 0.553486894349308, 0.5538361513096354, 0.5532618833091253, 0.5527953318012949, 0.5526174643384222, 0.5512264309179448, 0.5528727734790129, 0.5526987511254943, 0.5515872786950577, 0.5533026421009122, 0.5532549583469816, 0.5528796723355418, 0.5521248726321913, 0.5517116219872404, 0.5497298338795866, 0.5488079005609388, 0.5487826740955148, 0.5496101912939945, 0.5480163572618114, 0.547501610749213, 0.5478132333596955, 0.5461332503791965, 0.5464909324979843, 0.545991143645228, 0.5461714920180533, 0.5460457964931302, 0.5433491474908331, 0.5443120100690276, 0.5422961371176688, 0.5449575056200442, 0.5445893345129155, 0.5435728159402032, 0.543053788830862, 0.5448337287625389, 0.5437789171781686, 0.5454009793641622, 0.5407905093468058, 0.5429665288123329, 0.5431201519335017, 0.5447891055203765, 0.5424735962468035, 0.5415773836471846, 0.5414696871243474, 0.5419499932042778, 0.5403968467736793, 0.5421632675411147]\n",
            "Evaluation Accuracy after 300 epochs: 0.6303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "part 1B"
      ],
      "metadata": {
        "id": "6GMoeErskggQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "# Check for CUDA availability and set the device\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. Using GPU.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Using CPU.\")\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "metadata": {
        "id": "bOBvhtnijs_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified CNN model with an additional convolutional layer\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(32, 16, kernel_size=3, padding=1)  # Additional layer\n",
        "        self.act3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        # Adjusted fully connected layer\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 32)  # Adjust dimensions accordingly\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.act1(self.conv1(x)))\n",
        "        x = self.pool2(self.act2(self.conv2(x)))\n",
        "        x = self.pool3(self.act3(self.conv3(x)))  # Additional layer\n",
        "        x = x.view(-1, 16 * 4 * 4)  # Adjust view\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "-wD6Z5uDlNPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare CIFAR-10 dataset\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\n",
        "])\n"
      ],
      "metadata": {
        "id": "EMOssglOlQ-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = datasets.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(cifar10, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(cifar10_val, batch_size=64, shuffle=False)\n",
        "\n",
        "# Setup the model, optimizer, and loss function\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize variables for metrics\n",
        "total_training_time = 0\n",
        "epoch_losses = []\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjbC9BhTlT2g",
        "outputId": "8e45e54b-3b9d-438b-ff3b-120ee5225e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified training loop to record metrics\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    global total_training_time\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        end_time = time.time()\n",
        "        total_training_time += end_time - start_time\n",
        "        epoch_loss = loss_train / len(train_loader)\n",
        "        epoch_losses.append(epoch_loss)\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0 or epoch == n_epochs:\n",
        "            print(f'Epoch {epoch}, Training loss {epoch_loss}')\n"
      ],
      "metadata": {
        "id": "EgtGnGmGlWf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "import torch.nn.functional as F\n",
        "training_loop(\n",
        "    n_epochs=300,\n",
        "    optimizer=optimizer,\n",
        "    model=model,\n",
        "    loss_fn=loss_fn,\n",
        "    train_loader=train_loader\n",
        ")\n",
        "\n",
        "# Modified validation to record accuracy\n",
        "def validate(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += int((predicted == labels).sum())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "accuracy = validate(model, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYVnN8EHlYg-",
        "outputId": "9ad7ba07-3443-4794-f241-43d2bed532a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 2.2197195213773977\n",
            "Epoch 10, Training loss 1.1506458853211854\n",
            "Epoch 20, Training loss 0.8708154684899713\n",
            "Epoch 30, Training loss 0.7458834461010325\n",
            "Epoch 40, Training loss 0.6697807903103816\n",
            "Epoch 50, Training loss 0.6141825779091061\n",
            "Epoch 60, Training loss 0.573175831752665\n",
            "Epoch 70, Training loss 0.5383918472110768\n",
            "Epoch 80, Training loss 0.508937921594171\n",
            "Epoch 90, Training loss 0.4869399197456782\n",
            "Epoch 100, Training loss 0.46459664997008754\n",
            "Epoch 110, Training loss 0.4506819081275969\n",
            "Epoch 120, Training loss 0.43343013387811763\n",
            "Epoch 130, Training loss 0.42064590293847387\n",
            "Epoch 140, Training loss 0.4041229218549436\n",
            "Epoch 150, Training loss 0.39467144260168685\n",
            "Epoch 160, Training loss 0.3831133645437563\n",
            "Epoch 170, Training loss 0.37311083522370403\n",
            "Epoch 180, Training loss 0.36467875285869666\n",
            "Epoch 190, Training loss 0.3613382588567026\n",
            "Epoch 200, Training loss 0.3520490653679499\n",
            "Epoch 210, Training loss 0.34547489210772697\n",
            "Epoch 220, Training loss 0.3367704960524731\n",
            "Epoch 230, Training loss 0.3349677739221879\n",
            "Epoch 240, Training loss 0.3264518283174166\n",
            "Epoch 250, Training loss 0.31973265954638685\n",
            "Epoch 260, Training loss 0.31456889068264793\n",
            "Epoch 270, Training loss 0.31290996278567085\n",
            "Epoch 280, Training loss 0.307576314377053\n",
            "Epoch 290, Training loss 0.305118535742964\n",
            "Epoch 300, Training loss 0.29519910585430575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print or save the metrics\n",
        "print(f\"Total Training Time: {total_training_time:.2f} seconds\")\n",
        "print(f\"Training Losses Over Epochs: {epoch_losses}\")\n",
        "print(f\"Evaluation Accuracy after 300 epochs: {accuracy}\")\n",
        "\n",
        "# Optionally, write these metrics to a file\n",
        "with open(\"training_metrics.txt\", \"w\") as file:\n",
        "    file.write(f\"Total Training Time: {total_training_time:.2f} seconds\\n\")\n",
        "    file.write(f\"Training Losses Over Epochs: {epoch_losses}\\n\")\n",
        "    file.write(f\"Evaluation Accuracy after 300 epochs: {accuracy}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iOmHyw9lblP",
        "outputId": "0ab3a05d-9710-4e4c-e609-4b03e894e5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Training Time: 5096.12 seconds\n",
            "Training Losses Over Epochs: [2.2197195213773977, 1.8813542089498867, 1.6279902138063669, 1.5174160621050374, 1.427062135065913, 1.359341266819888, 1.2954430019916476, 1.2406638066482056, 1.1935176609269798, 1.1506458853211854, 1.1100826763436007, 1.0754650628475277, 1.0388733674498165, 1.0105130500195887, 0.9821785830933115, 0.9572325076745904, 0.9351888907230114, 0.9098549047699365, 0.8919203967389548, 0.8708154684899713, 0.8560184089424056, 0.8389412990921293, 0.8244503063085439, 0.8103245753613885, 0.7975292185230938, 0.7884911691669918, 0.775555870912569, 0.7645872495210994, 0.7565385330744716, 0.7458834461010325, 0.7364228954324332, 0.728327452336126, 0.718622481083626, 0.7127696617942332, 0.7025803407211133, 0.6953174155157851, 0.6895055943132972, 0.6823412343821562, 0.6753580051538585, 0.6697807903103816, 0.6639307386353802, 0.6575344444235878, 0.6519887934026816, 0.6473861254770737, 0.641550717603825, 0.6353230989345199, 0.6279636736568588, 0.6265532707085695, 0.6187682123592747, 0.6141825779091061, 0.6069263191631687, 0.6046617349700245, 0.5993877666838029, 0.5942307213307036, 0.5921396800243032, 0.5876440449291483, 0.5838892939107497, 0.5778235948222983, 0.5756943995309303, 0.573175831752665, 0.5677061840853728, 0.565336659074287, 0.5613408520474763, 0.5580852849556662, 0.5554548795037257, 0.5516311741431655, 0.546908802178967, 0.545854752554613, 0.5411353971418518, 0.5383918472110768, 0.5361407223107565, 0.5335670069546041, 0.5307239375417799, 0.5244119406280006, 0.5237295746879504, 0.5230369631515439, 0.5186544855689759, 0.5137993418194754, 0.5105228139006573, 0.508937921594171, 0.5065156425280339, 0.5050298208585176, 0.5019959407427427, 0.5000746298362228, 0.5003560332729079, 0.4946727134725627, 0.4912254525077008, 0.49078513960094405, 0.4890217487426365, 0.4869399197456782, 0.48574749407027384, 0.48142743550831707, 0.47843431370794925, 0.4768725352938218, 0.4772077357525106, 0.4737384902584888, 0.47276944074484395, 0.4695612719220579, 0.46798309737154287, 0.46459664997008754, 0.4677913990776862, 0.4630362556870941, 0.4646662923000048, 0.4591720513523082, 0.45560343904644635, 0.4534640749987891, 0.45312413378902106, 0.45138013017985523, 0.45099109876186344, 0.4506819081275969, 0.4467317722451961, 0.4442504892873642, 0.44637676225522593, 0.4413949179146296, 0.4407044695809369, 0.43995132508790097, 0.43643104748042955, 0.4376886469095259, 0.43399681343370694, 0.43343013387811763, 0.4295653375746954, 0.42974897319703453, 0.4286429606511465, 0.4261949191541623, 0.4238012559578547, 0.4220726626551212, 0.42410674927484654, 0.42054294575663176, 0.4206092886036009, 0.42064590293847387, 0.41630587831635, 0.4140992183476458, 0.41633670171127296, 0.4133833779017334, 0.41120035073641314, 0.4108351407682194, 0.4081456221049399, 0.4080187598305285, 0.40621750621730107, 0.4041229218549436, 0.4042988788060215, 0.40320455099996705, 0.40392383323301134, 0.4015422490094324, 0.4002354956801285, 0.39820397836739757, 0.3987083749469284, 0.3956046881501937, 0.3947692914387149, 0.39467144260168685, 0.3915249654056166, 0.39221531188930087, 0.38783901028544704, 0.3889072309522068, 0.38518595038091435, 0.38877356693605936, 0.3857133291718905, 0.3848912825288675, 0.3852793341859832, 0.3831133645437563, 0.38290664360232063, 0.3798399611573924, 0.3813085946757013, 0.382020613859834, 0.3792028133483494, 0.37756878105194674, 0.3769564475206768, 0.37448934975373166, 0.37529190776445676, 0.37311083522370403, 0.37706129281493406, 0.37083991227285634, 0.37137133185096716, 0.36970957928834974, 0.368530270626859, 0.36937013312297706, 0.3700039396562692, 0.3656732341670014, 0.36783371639945317, 0.36467875285869666, 0.36392800487063426, 0.36494010122840664, 0.3638284571106781, 0.3601117537397405, 0.3624399203969085, 0.362322366203341, 0.35936072628821253, 0.3592210490913952, 0.3603805085010541, 0.3613382588567026, 0.3585865667180332, 0.35841107624761587, 0.3541119368580144, 0.3549908062400263, 0.3560357265021947, 0.34894949745605974, 0.3518196047781526, 0.351602781783132, 0.3526761451702746, 0.3520490653679499, 0.34881233864123257, 0.34897484037729787, 0.3495570929801982, 0.345243741846298, 0.3455094979394732, 0.3485082001389597, 0.34513724772521603, 0.34640713574369547, 0.34538056783359067, 0.34547489210772697, 0.34160424116284344, 0.34217465325923224, 0.34040708972326933, 0.3423724423265061, 0.34034546043561853, 0.34018532338235385, 0.341331656898379, 0.3378711635308802, 0.3389746761306777, 0.3367704960524731, 0.3351410201862645, 0.3370598793277503, 0.33050154206697896, 0.33471196022866023, 0.3327684626078514, 0.334168147257603, 0.33132341130615195, 0.32997557439881825, 0.32966994885783973, 0.3349677739221879, 0.3300668962509431, 0.32772925284588733, 0.32375857855200463, 0.32918315634245765, 0.32750881879645233, 0.32832343000775716, 0.32880049278897705, 0.3272050765373975, 0.3277854984030699, 0.3264518283174166, 0.32675912373168087, 0.3239194106148637, 0.32201530919184007, 0.3212400512183871, 0.32514339793101904, 0.32140325228004807, 0.3206007546266479, 0.3208344922022289, 0.3214230529316094, 0.31973265954638685, 0.3235231274667451, 0.32120524821302776, 0.3191503106290117, 0.3174399215146861, 0.3164095570954978, 0.31289746100678467, 0.3182539287716379, 0.3189520022791365, 0.3189939466755256, 0.31456889068264793, 0.31297954418660734, 0.3113124848193372, 0.31338573833141486, 0.31570580610267035, 0.31274377524166763, 0.3098352073413103, 0.31128054692426604, 0.31242850669623945, 0.31091451317148133, 0.31290996278567085, 0.3128736807352594, 0.31274193002249273, 0.30896671743267945, 0.31404016791935774, 0.31247733049380505, 0.3051485114390283, 0.3108959752980553, 0.3108515358337051, 0.30808547882320325, 0.307576314377053, 0.30345660348034575, 0.3063813880981539, 0.305973270674572, 0.30551443900674813, 0.3063896928801942, 0.3016746085318153, 0.30765289331183715, 0.3038025589569298, 0.30462510004410964, 0.305118535742964, 0.30204695083982197, 0.3064414590425656, 0.2993603209533807, 0.30262174443972994, 0.30003564545165395, 0.3017356350941731, 0.3020395598067042, 0.2985786141927742, 0.3046494023040737, 0.29519910585430575]\n",
            "Evaluation Accuracy after 300 epochs: 0.6751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2A"
      ],
      "metadata": {
        "id": "3hqJ5wEemjhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "# Check for CUDA availability and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n"
      ],
      "metadata": {
        "id": "tpZ7ZTKRleOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ResNet block\n",
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "yCN0mnqHrTwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ResNet-10\n",
        "class ResNet10(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet10, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Create 10 ResNet blocks\n",
        "        self.layers = self._make_layers(ResNetBlock, 64, 10, stride=1)\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(64, 10)  # CIFAR-10 has 10 classes\n",
        "\n",
        "    def _make_layers(self, block, out_channels, num_blocks, stride):\n",
        "        layers = []\n",
        "        for _ in range(num_blocks):\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layers(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "czPP_5P8rWSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Create ResNet-10 model\n",
        "model = ResNet10().to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-uTiiv3rZI8",
        "outputId": "92cddd02-dcd3-4935-a0d0-846f7afcc3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 79907856.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(300):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/300], Loss: {running_loss / len(train_loader)}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_training_time = end_time - start_time\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on the test images: {accuracy}%')\n"
      ],
      "metadata": {
        "id": "jYD5ztYSrco7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaea0dc1-45d4-41ae-e96a-f18bb1638e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/300], Loss: 1.3700734099463734\n",
            "Epoch [2/300], Loss: 0.9747723994962395\n",
            "Epoch [3/300], Loss: 0.8167755990991812\n",
            "Epoch [4/300], Loss: 0.7069621771345358\n",
            "Epoch [5/300], Loss: 0.612974745080904\n",
            "Epoch [6/300], Loss: 0.5388997607981153\n",
            "Epoch [7/300], Loss: 0.4838336400516198\n",
            "Epoch [8/300], Loss: 0.43513788896448474\n",
            "Epoch [9/300], Loss: 0.3923194239968839\n",
            "Epoch [10/300], Loss: 0.36220576128234033\n",
            "Epoch [11/300], Loss: 0.3274009058161465\n",
            "Epoch [12/300], Loss: 0.3027380798250208\n",
            "Epoch [13/300], Loss: 0.27605625282010765\n",
            "Epoch [14/300], Loss: 0.24903656237418084\n",
            "Epoch [15/300], Loss: 0.22778127938890091\n",
            "Epoch [16/300], Loss: 0.2102278946229564\n",
            "Epoch [17/300], Loss: 0.18896981294426468\n",
            "Epoch [18/300], Loss: 0.17627362483907538\n",
            "Epoch [19/300], Loss: 0.15205721049319448\n",
            "Epoch [20/300], Loss: 0.14200500171164723\n",
            "Epoch [21/300], Loss: 0.13376207582061858\n",
            "Epoch [22/300], Loss: 0.11619356114064794\n",
            "Epoch [23/300], Loss: 0.10968716695542684\n",
            "Epoch [24/300], Loss: 0.10477202123178699\n",
            "Epoch [25/300], Loss: 0.09959316677163782\n",
            "Epoch [26/300], Loss: 0.08781259707020372\n",
            "Epoch [27/300], Loss: 0.09074617145806932\n",
            "Epoch [28/300], Loss: 0.07072137617041617\n",
            "Epoch [29/300], Loss: 0.07494546472549896\n",
            "Epoch [30/300], Loss: 0.0772264121324205\n",
            "Epoch [31/300], Loss: 0.061454462354331066\n",
            "Epoch [32/300], Loss: 0.06010158193986053\n",
            "Epoch [33/300], Loss: 0.06696443770157026\n",
            "Epoch [34/300], Loss: 0.05363335072413049\n",
            "Epoch [35/300], Loss: 0.06370317103946224\n",
            "Epoch [36/300], Loss: 0.05343071610816871\n",
            "Epoch [37/300], Loss: 0.04920956367374305\n",
            "Epoch [38/300], Loss: 0.05118448240801578\n",
            "Epoch [39/300], Loss: 0.054412496373857686\n",
            "Epoch [40/300], Loss: 0.046771633550715265\n",
            "Epoch [41/300], Loss: 0.037565635163527546\n",
            "Epoch [42/300], Loss: 0.048395259998967426\n",
            "Epoch [43/300], Loss: 0.047705513221518996\n",
            "Epoch [44/300], Loss: 0.041083000340710975\n",
            "Epoch [45/300], Loss: 0.03940267645029823\n",
            "Epoch [46/300], Loss: 0.03304689877149661\n",
            "Epoch [47/300], Loss: 0.05083045260885449\n",
            "Epoch [48/300], Loss: 0.03835514505915439\n",
            "Epoch [49/300], Loss: 0.036469843846869646\n",
            "Epoch [50/300], Loss: 0.04125351227267319\n",
            "Epoch [51/300], Loss: 0.029918695290875444\n",
            "Epoch [52/300], Loss: 0.03560993753080649\n",
            "Epoch [53/300], Loss: 0.028770756607046328\n",
            "Epoch [54/300], Loss: 0.045373990716736604\n",
            "Epoch [55/300], Loss: 0.028344935289753216\n",
            "Epoch [56/300], Loss: 0.030962664857887855\n",
            "Epoch [57/300], Loss: 0.0331417848760991\n",
            "Epoch [58/300], Loss: 0.02844071340457777\n",
            "Epoch [59/300], Loss: 0.028620017714181538\n",
            "Epoch [60/300], Loss: 0.024757858707874423\n",
            "Epoch [61/300], Loss: 0.040608446687207464\n",
            "Epoch [62/300], Loss: 0.030103530659747628\n",
            "Epoch [63/300], Loss: 0.021709233377565917\n",
            "Epoch [64/300], Loss: 0.026547018319036088\n",
            "Epoch [65/300], Loss: 0.032074196738741165\n",
            "Epoch [66/300], Loss: 0.028384493560294436\n",
            "Epoch [67/300], Loss: 0.02029944535510381\n",
            "Epoch [68/300], Loss: 0.031219942488676638\n",
            "Epoch [69/300], Loss: 0.030206114518196533\n",
            "Epoch [70/300], Loss: 0.020452522503449092\n",
            "Epoch [71/300], Loss: 0.02868168241471824\n",
            "Epoch [72/300], Loss: 0.021306988467579075\n",
            "Epoch [73/300], Loss: 0.021434211104725966\n",
            "Epoch [74/300], Loss: 0.022276713362889892\n",
            "Epoch [75/300], Loss: 0.026442084253332138\n",
            "Epoch [76/300], Loss: 0.02831288890245006\n",
            "Epoch [77/300], Loss: 0.023206135561472982\n",
            "Epoch [78/300], Loss: 0.02358865847020908\n",
            "Epoch [79/300], Loss: 0.01432608175107821\n",
            "Epoch [80/300], Loss: 0.0315142507854518\n",
            "Epoch [81/300], Loss: 0.02260326271724251\n",
            "Epoch [82/300], Loss: 0.01698127506322244\n",
            "Epoch [83/300], Loss: 0.020871605148123307\n",
            "Epoch [84/300], Loss: 0.020596708632413717\n",
            "Epoch [85/300], Loss: 0.024481928413686203\n",
            "Epoch [86/300], Loss: 0.01770409527810855\n",
            "Epoch [87/300], Loss: 0.015334071960244233\n",
            "Epoch [88/300], Loss: 0.02734457124816611\n",
            "Epoch [89/300], Loss: 0.022839116785899186\n",
            "Epoch [90/300], Loss: 0.01540044393717035\n",
            "Epoch [91/300], Loss: 0.014243096576335476\n",
            "Epoch [92/300], Loss: 0.0197924625591787\n",
            "Epoch [93/300], Loss: 0.02131689869513785\n",
            "Epoch [94/300], Loss: 0.016126269964403604\n",
            "Epoch [95/300], Loss: 0.018575324688244927\n",
            "Epoch [96/300], Loss: 0.010430969430527905\n",
            "Epoch [97/300], Loss: 0.022378862923224958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Report the training time, loss, and accuracy\n",
        "print(f\"Total Training Time: {total_training_time:.2f} seconds\")\n",
        "print(f\"Final Training Loss: {running_loss / len(train_loader)}\")\n",
        "print(f\"Test Accuracy: {accuracy}%\")\n"
      ],
      "metadata": {
        "id": "ETSgaK1trf69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oobktkcVrjgr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}